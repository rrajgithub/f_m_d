{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fmdipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdm0/gZXCncDUitGnk7EfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrajgithub/f_m_d/blob/main/fmd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd3jW3dlcgXv",
        "outputId": "f1f9fe0c-44a5-4e4c-b9e3-0e8ffd850e08"
      },
      "source": [
        "!git clone https://github.com/rrajgithub/f_m_d.git\n",
        "%cd f_m_d"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'f_m_d'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n",
            "/content/f_m_d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k14UwzHYclwb"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        " \n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\")\n",
        "model = load_model(\"mask_recog.h5\")\n",
        "\n",
        "def face_mask_detector(frame): \n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = faceCascade.detectMultiScale(gray,\n",
        "                                         scaleFactor=1.1,\n",
        "                                         minNeighbors=5,\n",
        "                                         minSize=(60, 60),\n",
        "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    faces_list=[]\n",
        "    preds=[]\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_frame = frame[y:y+h,x:x+w]\n",
        "        face_frame = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
        "        face_frame = cv2.resize(face_frame, (224, 224))\n",
        "        face_frame = img_to_array(face_frame)\n",
        "        face_frame = np.expand_dims(face_frame, axis=0)\n",
        "        face_frame =  preprocess_input(face_frame)\n",
        "        faces_list.append(face_frame)\n",
        "        if len(faces_list)>0:\n",
        "            preds = model.predict(faces_list)\n",
        "        for pred in preds:\n",
        "            (mask, withoutMask) = pred\n",
        "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "        cv2.putText(frame, label, (x, y- 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        " \n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
        "    return frame     "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGuWiAtKcqjw"
      },
      "source": [
        "input_image=cv2.imread(\"image.jpg\")\n",
        "output=face_mask_detector(input_image)\n",
        "cv2_imshow(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLt3o4E7ctNl",
        "outputId": "67715119-a3af-48a6-d22a-4666d6b742a6"
      },
      "source": [
        "cap=cv2.VideoCapture('video.mp4')\n",
        "ret,frame=cap.read()\n",
        "frame_height,frame_width, _=frame.shape\n",
        "out=cv2.VideoWriter('output.mp4',cv2.VideoWriter_fourcc('M','J','P','G'),10,(frame_width,frame_height))\n",
        "\n",
        "print(\"processing video..\")\n",
        "while cap.isOpened():\n",
        "  ret,frame=cap.read()\n",
        "  if not ret:\n",
        "    out.release()\n",
        "    break\n",
        "  output=face_mask_detector(frame)\n",
        "  out.write(output)\n",
        "out.release()\n",
        "print(\"done processing video\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing video..\n",
            "done processing video\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}